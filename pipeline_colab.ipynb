{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# De-identification Pipeline (Colab Version)\n",
        "\n",
        "This notebook runs the full media de-identification pipeline based on your `pipeline_batch.py` script.\n",
        "\n",
        "**Features:**\n",
        "1. Downloads video from YouTube.\n",
        "2. Extracts audio for transcription.\n",
        "3. Blurs faces in the video (Optimized for Colab/CPU).\n",
        "4. Transcribes audio using Azure Speech-to-Text.\n",
        "5. Redacts PHI from the transcript using Azure Health De-identification.\n",
        "6. Recombines processed video and audio.\n",
        "\n",
        "**Setup:**\n",
        "1. Set your Azure secrets in the Configuration cell.\n",
        "2. Enable GPU runtime (Runtime > Change runtime type > T4 GPU) for best performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "!pip install azure-cognitiveservices-speech azure-health-deidentification azure-identity azure-storage-blob yt-dlp opencv-python-headless numpy requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports-setup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "import yt_dlp\n",
        "import cv2\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
        "from azure.health.deidentification import DeidentificationClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# TODO: Replace these with your actual keys\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=IrCmLrUXdmo\" \n",
        "SPEECH_KEY = \"YOUR_SPEECH_KEY\"\n",
        "SPEECH_REGION = \"eastus\"\n",
        "DEID_SERVICE_ENDPOINT = \"YOUR_DEID_ENDPOINT\"\n",
        "STORAGE_CONN_STR = \"YOUR_STORAGE_CONNECTION_STRING\"\n",
        "\n",
        "if SPEECH_KEY == \"YOUR_SPEECH_KEY\":\n",
        "    print(\"WARNING: You need to set your Azure API keys in this cell!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "helper-functions"
      },
      "outputs": [],
      "source": [
        "def download_video_and_extract_audio(youtube_url, output_filename=\"colab_media\"):\n",
        "    print(f\"Downloading video from {youtube_url}...\")\n",
        "    ydl_opts = {\n",
        "        'format': 'best[ext=mp4]/best',\n",
        "        'outtmpl': output_filename + '.%(ext)s',\n",
        "        'quiet': True,\n",
        "    }\n",
        "    video_path = f\"{output_filename}.mp4\"\n",
        "    audio_path = f\"{output_filename}.wav\"\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "        \n",
        "        if not os.path.exists(video_path):\n",
        "            for f in os.listdir(\".\"):\n",
        "                if f.startswith(output_filename) and not f.endswith(\".wav\"):\n",
        "                    video_path = f\n",
        "                    break\n",
        "        \n",
        "        print(f\"Video downloaded: {video_path}\")\n",
        "        \n",
        "        print(\"Extracting audio...\")\n",
        "        subprocess.run([\n",
        "            'ffmpeg', '-y', '-i', video_path, \n",
        "            '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', \n",
        "            audio_path\n",
        "        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        \n",
        "        return video_path, audio_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def blur_faces(video_path, output_path):\n",
        "    \"\"\"\n",
        "    Blurs faces in the video. Includes resizing optimization for faster processing.\n",
        "    \"\"\"\n",
        "    print(f\"Blurring faces in {video_path}...\")\n",
        "    \n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    \n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    \n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Optimization: Detect on smaller image to speed up CPU processing\n",
        "    scale_factor = 0.5 \n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "            \n",
        "        # Resize for detection\n",
        "        small_frame = cv2.resize(frame, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "        gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
        "        \n",
        "        for (x, y, w, h) in faces:\n",
        "            # Scale coordinates back to original size\n",
        "            x = int(x / scale_factor)\n",
        "            y = int(y / scale_factor)\n",
        "            w = int(w / scale_factor)\n",
        "            h = int(h / scale_factor)\n",
        "            \n",
        "            # Bounds check\n",
        "            y_end = min(height, y+h)\n",
        "            x_end = min(width, x+w)\n",
        "            \n",
        "            if y < y_end and x < x_end:\n",
        "                roi = frame[y:y_end, x:x_end]\n",
        "                roi = cv2.GaussianBlur(roi, (99, 99), 30)\n",
        "                frame[y:y_end, x:x_end] = roi\n",
        "            \n",
        "        out.write(frame)\n",
        "        \n",
        "        frame_count += 1\n",
        "        if frame_count % 500 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            fps_proc = frame_count / elapsed\n",
        "            eta_min = (total_frames - frame_count) / fps_proc / 60\n",
        "            print(f\"Processed {frame_count}/{total_frames} frames. Speed: {fps_proc:.2f} fps. ETA: {eta_min:.1f} min\")\n",
        "            \n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Blurring complete: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def upload_to_blob(file_path, connection_string, container_name=\"colab-uploads\"):\n",
        "    try:\n",
        "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "        container_client = blob_service_client.get_container_client(container_name)\n",
        "        if not container_client.exists(): container_client.create_container()\n",
        "        blob_name = os.path.basename(file_path)\n",
        "        blob_client = container_client.get_blob_client(blob_name)\n",
        "        with open(file_path, \"rb\") as data:\n",
        "            blob_client.upload_blob(data, overwrite=True)\n",
        "        sas_token = generate_blob_sas(\n",
        "            account_name=blob_client.account_name,\n",
        "            container_name=container_name,\n",
        "            blob_name=blob_name,\n",
        "            account_key=blob_service_client.credential.account_key,\n",
        "            permission=BlobSasPermissions(read=True),\n",
        "            expiry=datetime.now(timezone.utc) + timedelta(hours=24)\n",
        "        )\n",
        "        return f\"{blob_client.url}?{sas_token}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Blob upload error: {e}\")\n",
        "        return None\n",
        "\n",
        "def submit_transcription_job(audio_url, speech_key, speech_region):\n",
        "    api_url = f\"https://{speech_region}.api.cognitive.microsoft.com/speechtotext/v3.1/transcriptions\"\n",
        "    headers = {\"Ocp-Apim-Subscription-Key\": speech_key, \"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"displayName\": f\"colab_transcription_{int(time.time())}\",\n",
        "        \"description\": \"De-identification POC Colab\",\n",
        "        \"locale\": \"en-US\",\n",
        "        \"contentUrls\": [audio_url],\n",
        "        \"properties\": {\"wordLevelTimestampsEnabled\": False, \"punctuationMode\": \"DictatedAndAutomatic\"}\n",
        "    }\n",
        "    response = requests.post(api_url, headers=headers, json=payload)\n",
        "    if response.status_code == 201:\n",
        "        return response.json()[\"self\"]\n",
        "    print(f\"Transcription submission failed: {response.text}\")\n",
        "    return None\n",
        "\n",
        "def wait_for_transcript(job_url, speech_key):\n",
        "    headers = {\"Ocp-Apim-Subscription-Key\": speech_key}\n",
        "    while True:\n",
        "        response = requests.get(job_url, headers=headers)\n",
        "        status = response.json()[\"status\"]\n",
        "        if status == \"Succeeded\": break\n",
        "        if status == \"Failed\": return None\n",
        "        time.sleep(10)\n",
        "    \n",
        "    results_url = response.json()[\"links\"][\"files\"]\n",
        "    files = requests.get(results_url, headers=headers).json()[\"values\"]\n",
        "    for f in files:\n",
        "        if f[\"kind\"] == \"Transcription\":\n",
        "            data = requests.get(f[\"links\"][\"contentUrl\"]).json()\n",
        "            return \" \".join([p[\"display\"] for p in data[\"combinedRecognizedPhrases\"]])\n",
        "    return None\n",
        "\n",
        "def redact_phi(text, endpoint):\n",
        "    try:\n",
        "        credential = DefaultAzureCredential()\n",
        "        client = DeidentificationClient(endpoint=endpoint, credential=credential)\n",
        "        # Chunking for API limits\n",
        "        chunk_size = 5000\n",
        "        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "        redacted_chunks = []\n",
        "        for chunk in chunks:\n",
        "            response = client.deidentify_text(body={\"inputText\": chunk})\n",
        "            redacted_chunks.append(response.output_text)\n",
        "        return \"\".join(redacted_chunks)\n",
        "    except Exception as e:\n",
        "        print(f\"Redaction error/skipped: {e}\")\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main-execution"
      },
      "outputs": [],
      "source": [
        "# --- RUN PIPELINE ---\n",
        "print(\"=== Step 1: Download ===\")\n",
        "video_path, audio_path = download_video_and_extract_audio(YOUTUBE_URL)\n",
        "\n",
        "if video_path:\n",
        "    print(\"\\n=== Step 2: Face Blurring (Optimized) ===\")\n",
        "    blurred_output = \"colab_blurred_silent.mp4\"\n",
        "    blur_faces(video_path, blurred_output)\n",
        "    \n",
        "    print(\"\\n=== Step 3: Transcription & De-ID ===\")\n",
        "    if SPEECH_KEY != \"YOUR_SPEECH_KEY\":\n",
        "        sas_url = upload_to_blob(audio_path, STORAGE_CONN_STR)\n",
        "        if sas_url:\n",
        "            job = submit_transcription_job(sas_url, SPEECH_KEY, SPEECH_REGION)\n",
        "            if job:\n",
        "                transcript = wait_for_transcript(job, SPEECH_KEY)\n",
        "                print(f\"Transcript preview: {transcript[:100]}...\")\n",
        "                # redacted = redact_phi(transcript, DEID_SERVICE_ENDPOINT) \n",
        "                # print(f\"Redacted: {redacted[:100]}\")\n",
        "    else:\n",
        "        print(\"Skipping Cloud steps (Keys not set).\")\n",
        "    \n",
        "    print(\"\\n=== Step 4: Final Merge ===\")\n",
        "    final_output = \"colab_final_deidentified.mp4\"\n",
        "    subprocess.run([\n",
        "        'ffmpeg', '-y', '-i', blurred_output, '-i', audio_path, \n",
        "        '-c:v', 'copy', '-c:a', 'aac', final_output\n",
        "    ])\n",
        "    print(f\"DONE! Output: {final_output}\")\n",
        "    \n",
        "    # Helper to download file in Colab\n",
        "    from google.colab import files\n",
        "    files.download(final_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
